[args]
bert_model=./roberta-base
root_data_dir=datasets_with_WPDom/verbparse_deparser_domain_scores/
model=WPDM
mlp_layers=2
task_name=VUA_Verb
word_type=verbal
classifier_hidden=768
label_size=2
lr_schedule=warmup
warmup_epoch=2
drop_ratio=0.5
kfold=10
max_seq_length=200
do_train=True
do_test=True
do_eval=True
do_lower_case=True
hidden_size=768
train_batch_size=512
eval_batch_size=512
num_train_epoch=20
grad_clip_norm=1.0
save_checkpoint=False
save_best_model=False
model_root_path=saves/
seed=42
temp=0.05
learning_rate=0.003
weight_decay=0.01
optimizer=Adam
module_name=encoder, classifier
module_lr=(3e-05, 0.003)
module_weight_decay=(0.01, 0.01)
word_emb_type=mean
word_pair_max=3
segment=none
spec_tok=False
cls_num=3
tau_max=10
attention_layer=2
ffn_size=768
multihead=2
average=False
main_conf_path=
class_weight=2
model_path=saves/VUA_Verb/verbal
data_dir=datasets_with_WPDom/verbparse_deparser_domain_scores/VUA_Verb

